{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW2_NEURON_NETWORKS.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOysX58mgILFOm/iYNTwc/k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YaeliBarGimelshtein/ML-NN/blob/main/HW2_NEURON_NETWORKS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8aPlKLZrJ1A"
      },
      "source": [
        "#Home Work 2: Creating XOR Learning Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TRp_QZ2rVDj"
      },
      "source": [
        "#IMPORTS\n",
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tc-nsgUart0g"
      },
      "source": [
        "יצירת מחלקה שמייצגת שכבה ברשת הניורונים"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erenX2-HrXis"
      },
      "source": [
        "#CREATING CLASS LAYER\n",
        "class Layer(nn.Module):\n",
        "  def __init__(self, in_features: int, out_features: int, bias: bool = True, device=None, dtype=None) -> None:\n",
        "    factory_kwargs = {'device': device, 'dtype': dtype}\n",
        "    super(Layer, self).__init__()\n",
        "    self.in_features = in_features\n",
        "    self.out_features = out_features\n",
        "    self.weight = nn.Parameter(torch.empty((in_features, out_features), **factory_kwargs))\n",
        "    if bias:\n",
        "        self.bias = nn.Parameter(torch.empty(out_features, **factory_kwargs))\n",
        "    else:\n",
        "        self.register_parameter('bias', None)\n",
        "    self.reset_parameters()\n",
        "\n",
        "  def reset_parameters(self) -> None:\n",
        "    self.weight = nn.Parameter(torch.rand([self.in_features, self.out_features]))\n",
        "    if self.bias is not None:\n",
        "      self.bias = nn.Parameter(torch.rand([self.out_features]))\n",
        "\n",
        "  def set_weights(self, w, b):\n",
        "    self.weight = nn.Parameter(torch.tensor(w))\n",
        "    self.bias = nn.Parameter(torch.tensor(b))\n",
        "    \n",
        "  def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
        "   return torch.matmul(input, self.weight) + self.bias\n",
        "   \n",
        "\n",
        "\n",
        "  def extra_repr(self) -> str:\n",
        "    return 'in_features={}, out_features={}, bias={}'.format(\n",
        "        self.in_features, self.out_features, self.bias is not None\n",
        "      )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVTartsDrxoZ"
      },
      "source": [
        "יצירת מחלקה סיגמואיד שמהווה את פונקצית האקטיבציה של ניורון (אם ירה או לא)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Zq34An6raYd"
      },
      "source": [
        "#CREATING CLASS SIGMOID AS ACTIVATION FUNCTION\n",
        "class Sigmoid(nn.Module):\n",
        "  def __init__(self, T=0.2):\n",
        "      super(Sigmoid, self).__init__()\n",
        "      self.T = T\n",
        "\n",
        "  def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
        "      return 1 / (1 + torch.exp(-input/self.T))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlyQQjfDr02w"
      },
      "source": [
        "מחלקה שמהווה רשת פשוטה של ניורונים : שכבת קלט שכבה אחת נסתרת ושכבת פלט"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vr2H5INzrdX1"
      },
      "source": [
        "#CREATING CLASS NETWORK AS NEURON NETWORK\n",
        "class Network(nn.Module):\n",
        "  def __init__(self, k, input_nums, bypass=False):\n",
        "    super().__init__()\n",
        "    self.input_nums = input_nums\n",
        "    self.output_num = 1\n",
        "    self.Temp = 0.5\n",
        "    self.bypass = bypass\n",
        "    self.k = k\n",
        "    self.hidden = Layer(self.input_nums, self.k)\n",
        "    if self.bypass:\n",
        "      self.output = Layer(self.k + self.input_nums, self.output_num)\n",
        "    else:\n",
        "      self.output = Layer(self.k, self.output_num)\n",
        "    self.Sigmoid = Sigmoid(self.Temp)\n",
        "  \n",
        "  def forward(self, input: torch.Tensor):\n",
        "    z1 = self.hidden.forward(input)\n",
        "    y1 = self.Sigmoid.forward(z1)\n",
        "\n",
        "    if self.k == 1:\n",
        "        print(input, \" --> \", y1)\n",
        "\n",
        "    if self.bypass:\n",
        "      y1_concat = torch.cat((input, y1), 1)\n",
        "      z2 = self.output.forward(y1_concat)\n",
        "    else:\n",
        "      z2 = self.output.forward(y1)\n",
        "    return self.Sigmoid.forward(z2)\n",
        "  \n",
        "  def set_weights(self, w: torch.Tensor, b: torch.Tensor, layer_name):\n",
        "    if layer_name == \"hidden\":\n",
        "      if w.size() != (self.input_nums, self.k):\n",
        "        print(\"wrong size of weights\")\n",
        "        return\n",
        "\n",
        "      if b.size() != (1, self.k):\n",
        "        print(\"wrong size of bias\")\n",
        "        return\n",
        "      \n",
        "      self.hidden.set_weights(w,b)\n",
        "\n",
        "    \n",
        "    if layer_name == \"output\":\n",
        "      if self.bypass:\n",
        "        if w.size() != (self.k + self.input_nums, self.output_num):\n",
        "          print(\"wrong size of weights\")\n",
        "          return\n",
        "      else:\n",
        "        if w.size() != (self.k, self.output_num):\n",
        "          print(\"wrong size of weights\")\n",
        "          return\n",
        "      \n",
        "      if b.size() != (1, 1):\n",
        "        print(\"wrong size of bias\")\n",
        "        return\n",
        "\n",
        "      self.output.set_weights(w,b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ei75hPj_cJ7"
      },
      "source": [
        "![k= 4.jpg](data:image/jpeg;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5rHpQeMr6ul"
      },
      "source": [
        "פונקציה שבודקת את היעילות של הרשת הזו"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GN-uTa0_rgIy"
      },
      "source": [
        "def Loss(out, t_train):\n",
        "  return -torch.sum(t_train * torch.log(out) + (1.0 - t_train) * torch.log(1.0 - out))  # Cross Entropy loss function"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwAEG4Ug_uT3"
      },
      "source": [
        "![ce.jpg](data:image/jpeg;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IR5SXeB1uFZ3"
      },
      "source": [
        "פונקציה שמבצעת למידה ומעדנת משקולות"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKDirX_nrm_a"
      },
      "source": [
        "def train(network, x_train, t_train, optimizer):\n",
        "  y_pred = network.forward(x_train) #returns the prediction\n",
        "  loss = Loss(y_pred, t_train) #calcs CE error\n",
        "\n",
        "  #GD METHOD\n",
        "  # zero gradients berfore running the backward pass --> gradient = zero\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # backward pass to compute the gradient of loss\n",
        "  # backprop + accumulate \n",
        "  loss.backward()\n",
        "\n",
        "  # update params\n",
        "  optimizer.step() # weights = weights + delta\n",
        "  return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RI12lM8mxefZ"
      },
      "source": [
        "הקבועים עבור כל הניסויים"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DONMnlj-viD0"
      },
      "source": [
        "#ALL CONSTS\n",
        "max_epochs = 40000\n",
        "good_validation_loss = 0.2\n",
        "\n",
        "#train\n",
        "train_set = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
        "train_target = torch.tensor([[0], [1], [1], [0]], dtype=torch.float32)\n",
        "\n",
        "#validation\n",
        "validation_set = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1] , [1,0.1], [1,0.9], [0.9,0.9], [0.1,0.9]], dtype=torch.float32)\n",
        "validation_target = torch.tensor([[0], [1], [1], [0],[1],[0],[0],[1]], dtype=torch.float32)\n",
        "\n",
        "#input\n",
        "input_nums = 2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPvSU7-xxyU2"
      },
      "source": [
        "ניצור פונקציה שתהיה הלולאה הנידרשת ללמידה עם 2 תנאי העצירה"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoanfT9ax4Up"
      },
      "source": [
        "#THE LOOP\n",
        "def expiriment(k , Learning_rate, Bypass):\n",
        "  model = Network(k, input_nums, bypass= Bypass)\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=Learning_rate)\n",
        "\n",
        "  old_validation_loss = 0\n",
        "  counter_loops = 0\n",
        "\n",
        "  #create the loop\n",
        "  for i in range(max_epochs):\n",
        "    train_loss= train(model, train_set, train_target, optimizer) #training\n",
        "    validation_loss = Loss(model.forward(validation_set), validation_target) #validating\n",
        "\n",
        "    #check counter\n",
        "    if validation_loss - old_validation_loss < 0.0001:\n",
        "      counter_loops += 1\n",
        "    else:\n",
        "      counter_loops = 0\n",
        "    # success\n",
        "    if validation_loss < good_validation_loss and counter_loops >= 10:\n",
        "      return (1, i, validation_loss, train_loss)\n",
        "    \n",
        "    old_validation_loss = validation_loss\n",
        "  \n",
        "  return (0, 0, 0, 0)\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUogbIHdu-kO"
      },
      "source": [
        "ניסוי 1 \n",
        "\n",
        "Learning rate = 0.1 , k = 4 , Bypass=True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIvtWifCvVQM",
        "outputId": "0bd85ed1-314f-45ba-9207-c7f360762b02"
      },
      "source": [
        "k1 = 4\n",
        "Learning_rate1 = 0.1\n",
        "bypass1 = True\n",
        "\n",
        "counter = 0\n",
        "fail_counter = 0\n",
        "data = {}\n",
        "list_epochs = []\n",
        "list_train_loss = []\n",
        "list_validation_loss = []\n",
        "\n",
        "while counter < 10:\n",
        "    (succes, num_epochs, validation_loss, train_loss) = expiriment(k1, Learning_rate1, bypass1)\n",
        "    if succes == 1:\n",
        "      data[counter] =  (num_epochs, validation_loss, train_loss)\n",
        "      list_epochs.append(num_epochs)\n",
        "      list_train_loss.append(train_loss.detach().numpy())\n",
        "      list_validation_loss.append(validation_loss.detach().numpy())\n",
        "      counter +=1\n",
        "    else:\n",
        "      fail_counter +=1\n",
        "\n",
        "#AVG\n",
        "avg_epochs1 = np.average(list_epochs)\n",
        "avg_train_loss = np.average(list_train_loss)\n",
        "avg_validation_loss = np.average(list_validation_loss)\n",
        "\n",
        "#STD\n",
        "std_epochs1 = np.std(list_epochs)\n",
        "std_train_loss = np.std(list_train_loss)\n",
        "std_validation_loss = np.std(list_validation_loss)\n",
        "\n",
        "#PRINT\n",
        "for i in range (10):\n",
        "  print(data[i])\n",
        "\n",
        "print()\n",
        "print(\"AVG:\")\n",
        "print(\"epochs = \", avg_epochs1, \"train loss = \", avg_train_loss, \"validation loss= \", avg_validation_loss)\n",
        "\n",
        "print()\n",
        "print(\"STD:\")\n",
        "print(\"epochs = \", std_epochs1, \"train loss = \", std_train_loss, \"validation loss= \", std_validation_loss)\n",
        "\n",
        "print()\n",
        "print(\"failed tries = \", fail_counter)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(771, tensor(0.1997, grad_fn=<NegBackward>), tensor(0.0525, grad_fn=<NegBackward>))\n",
            "(562, tensor(0.1998, grad_fn=<NegBackward>), tensor(0.0666, grad_fn=<NegBackward>))\n",
            "(636, tensor(0.1999, grad_fn=<NegBackward>), tensor(0.0539, grad_fn=<NegBackward>))\n",
            "(658, tensor(0.1999, grad_fn=<NegBackward>), tensor(0.0547, grad_fn=<NegBackward>))\n",
            "(710, tensor(0.1998, grad_fn=<NegBackward>), tensor(0.0542, grad_fn=<NegBackward>))\n",
            "(836, tensor(0.1999, grad_fn=<NegBackward>), tensor(0.0497, grad_fn=<NegBackward>))\n",
            "(662, tensor(0.1998, grad_fn=<NegBackward>), tensor(0.0601, grad_fn=<NegBackward>))\n",
            "(1392, tensor(0.1999, grad_fn=<NegBackward>), tensor(0.0467, grad_fn=<NegBackward>))\n",
            "(765, tensor(0.1999, grad_fn=<NegBackward>), tensor(0.0578, grad_fn=<NegBackward>))\n",
            "(749, tensor(0.2000, grad_fn=<NegBackward>), tensor(0.0511, grad_fn=<NegBackward>))\n",
            "\n",
            "AVG:\n",
            "epochs =  774.1 train loss =  0.054728247 validation loss=  0.19986364\n",
            "\n",
            "STD:\n",
            "epochs =  219.21836145724654 train loss =  0.005373509 validation loss=  6.8170986e-05\n",
            "\n",
            "failed tries =  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2XYZeiS959X"
      },
      "source": [
        "ניסוי 2\n",
        "\n",
        "Learning rate = 0.1 , k = 4 , Bypass= False"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jNBj9VcDvJ1",
        "outputId": "f0a426fc-8363-41c7-902c-acdad6b38b6a"
      },
      "source": [
        "k2 = 4\n",
        "Learning_rate2 = 0.1\n",
        "bypass2 = False\n",
        "\n",
        "counter = 0\n",
        "fail_counter = 0\n",
        "data = {}\n",
        "list_epochs = []\n",
        "list_train_loss = []\n",
        "list_validation_loss = []\n",
        "\n",
        "while counter < 10:\n",
        "    (succes, num_epochs, validation_loss, train_loss) = expiriment(k2, Learning_rate2, bypass2)\n",
        "    if succes == 1:\n",
        "      data[counter] =  (num_epochs, validation_loss, train_loss)\n",
        "      list_epochs.append(num_epochs)\n",
        "      list_train_loss.append(train_loss.detach().numpy())\n",
        "      list_validation_loss.append(validation_loss.detach().numpy())\n",
        "      counter +=1\n",
        "    else:\n",
        "      fail_counter +=1\n",
        "\n",
        "#AVG\n",
        "avg_epochs2 = np.average(list_epochs)\n",
        "avg_train_loss = np.average(list_train_loss)\n",
        "avg_validation_loss = np.average(list_validation_loss)\n",
        "\n",
        "#STD\n",
        "std_epochs2 = np.std(list_epochs)\n",
        "std_train_loss = np.std(list_train_loss)\n",
        "std_validation_loss = np.std(list_validation_loss)\n",
        "\n",
        "#PRINT\n",
        "for i in range (10):\n",
        "  print(data[i])\n",
        "\n",
        "print()\n",
        "print(\"AVG:\")\n",
        "print(\"epochs = \", avg_epochs2, \"train loss = \", avg_train_loss, \"validation loss= \", avg_validation_loss)\n",
        "\n",
        "print()\n",
        "print(\"STD:\")\n",
        "print(\"epochs = \", std_epochs2, \"train loss = \", std_train_loss, \"validation loss= \", std_validation_loss)\n",
        "\n",
        "print()\n",
        "print(\"failed tries = \", fail_counter)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(519, tensor(0.1995, grad_fn=<NegBackward>), tensor(0.0639, grad_fn=<NegBackward>))\n",
            "(612, tensor(0.1996, grad_fn=<NegBackward>), tensor(0.0623, grad_fn=<NegBackward>))\n",
            "(617, tensor(0.1997, grad_fn=<NegBackward>), tensor(0.0684, grad_fn=<NegBackward>))\n",
            "(635, tensor(0.1996, grad_fn=<NegBackward>), tensor(0.0692, grad_fn=<NegBackward>))\n",
            "(558, tensor(0.1995, grad_fn=<NegBackward>), tensor(0.0670, grad_fn=<NegBackward>))\n",
            "(539, tensor(0.1996, grad_fn=<NegBackward>), tensor(0.0670, grad_fn=<NegBackward>))\n",
            "(622, tensor(0.1999, grad_fn=<NegBackward>), tensor(0.0675, grad_fn=<NegBackward>))\n",
            "(734, tensor(0.1999, grad_fn=<NegBackward>), tensor(0.0695, grad_fn=<NegBackward>))\n",
            "(605, tensor(0.1997, grad_fn=<NegBackward>), tensor(0.0675, grad_fn=<NegBackward>))\n",
            "(544, tensor(0.1996, grad_fn=<NegBackward>), tensor(0.0638, grad_fn=<NegBackward>))\n",
            "\n",
            "AVG:\n",
            "epochs =  598.5 train loss =  0.066607006 validation loss=  0.19966409\n",
            "\n",
            "STD:\n",
            "epochs =  59.3990740668573 train loss =  0.0023136868 validation loss=  0.00014176335\n",
            "\n",
            "failed tries =  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lm8FkYOA-Da3"
      },
      "source": [
        "ניסוי 3\n",
        "\n",
        "Learning rate = 0.1 , k = 2 , Bypass=True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqmVDFeADzJ_",
        "outputId": "ba3d3101-6948-4c58-e6b4-98e4426de4f5"
      },
      "source": [
        "k3 = 2\n",
        "Learning_rate3 = 0.1\n",
        "bypass3 = True\n",
        "\n",
        "counter = 0\n",
        "fail_counter = 0\n",
        "data = {}\n",
        "list_epochs = []\n",
        "list_train_loss = []\n",
        "list_validation_loss = []\n",
        "\n",
        "while counter < 10:\n",
        "    (succes, num_epochs, validation_loss, train_loss) = expiriment(k3, Learning_rate3, bypass3)\n",
        "    if succes == 1:\n",
        "      data[counter] =  (num_epochs, validation_loss, train_loss)\n",
        "      list_epochs.append(num_epochs)\n",
        "      list_train_loss.append(train_loss.detach().numpy())\n",
        "      list_validation_loss.append(validation_loss.detach().numpy())\n",
        "      counter +=1\n",
        "    else:\n",
        "      fail_counter +=1\n",
        "\n",
        "#AVG\n",
        "avg_epochs3 = np.average(list_epochs)\n",
        "avg_train_loss = np.average(list_train_loss)\n",
        "avg_validation_loss = np.average(list_validation_loss)\n",
        "\n",
        "#STD\n",
        "std_epochs3 = np.std(list_epochs)\n",
        "std_train_loss = np.std(list_train_loss)\n",
        "std_validation_loss = np.std(list_validation_loss)\n",
        "\n",
        "#PRINT\n",
        "for i in range (10):\n",
        "  print(data[i])\n",
        "\n",
        "print()\n",
        "print(\"AVG:\")\n",
        "print(\"epochs = \", avg_epochs3, \"train loss = \", avg_train_loss, \"validation loss= \", avg_validation_loss)\n",
        "\n",
        "print()\n",
        "print(\"STD:\")\n",
        "print(\"epochs = \", std_epochs3, \"train loss = \", std_train_loss, \"validation loss= \", std_validation_loss)\n",
        "\n",
        "print()\n",
        "print(\"failed tries = \", fail_counter)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(982, tensor(0.1999, grad_fn=<NegBackward>), tensor(0.0528, grad_fn=<NegBackward>))\n",
            "(931, tensor(0.2000, grad_fn=<NegBackward>), tensor(0.0508, grad_fn=<NegBackward>))\n",
            "(925, tensor(0.1999, grad_fn=<NegBackward>), tensor(0.0522, grad_fn=<NegBackward>))\n",
            "(1477, tensor(0.1999, grad_fn=<NegBackward>), tensor(0.0451, grad_fn=<NegBackward>))\n",
            "(1383, tensor(0.1999, grad_fn=<NegBackward>), tensor(0.0439, grad_fn=<NegBackward>))\n",
            "(1518, tensor(0.1999, grad_fn=<NegBackward>), tensor(0.0456, grad_fn=<NegBackward>))\n",
            "(724, tensor(0.1998, grad_fn=<NegBackward>), tensor(0.0599, grad_fn=<NegBackward>))\n",
            "(1467, tensor(0.2000, grad_fn=<NegBackward>), tensor(0.0457, grad_fn=<NegBackward>))\n",
            "(1175, tensor(0.2000, grad_fn=<NegBackward>), tensor(0.0504, grad_fn=<NegBackward>))\n",
            "(936, tensor(0.1998, grad_fn=<NegBackward>), tensor(0.0522, grad_fn=<NegBackward>))\n",
            "\n",
            "AVG:\n",
            "epochs =  1151.8 train loss =  0.049865913 validation loss=  0.19990867\n",
            "\n",
            "STD:\n",
            "epochs =  274.19073653207175 train loss =  0.004652912 validation loss=  5.6569796e-05\n",
            "\n",
            "failed tries =  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3eOZlYj-QEx"
      },
      "source": [
        "ניסוי 4\n",
        "\n",
        "Learning rate = 0.1 , k = 2 , Bypass= False"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKZPudmWD2GT",
        "outputId": "8e2dc1ea-d930-4cf3-9cc5-0cac66e514a1"
      },
      "source": [
        "k4 = 2\n",
        "Learning_rate4 = 0.1\n",
        "bypass4 = False\n",
        "\n",
        "counter = 0\n",
        "fail_counter = 0\n",
        "data = {}\n",
        "list_epochs = []\n",
        "list_train_loss = []\n",
        "list_validation_loss = []\n",
        "\n",
        "while counter < 10:\n",
        "    (succes, num_epochs, validation_loss, train_loss) = expiriment(k4, Learning_rate4, bypass4)\n",
        "    if succes == 1:\n",
        "      data[counter] =  (num_epochs, validation_loss, train_loss)\n",
        "      list_epochs.append(num_epochs)\n",
        "      list_train_loss.append(train_loss.detach().numpy())\n",
        "      list_validation_loss.append(validation_loss.detach().numpy())\n",
        "      counter +=1\n",
        "    else:\n",
        "      fail_counter +=1\n",
        "\n",
        "#AVG\n",
        "avg_epochs4 = np.average(list_epochs)\n",
        "avg_train_loss = np.average(list_train_loss)\n",
        "avg_validation_loss = np.average(list_validation_loss)\n",
        "\n",
        "#STD\n",
        "std_epochs4 = np.std(list_epochs)\n",
        "std_train_loss = np.std(list_train_loss)\n",
        "std_validation_loss = np.std(list_validation_loss)\n",
        "\n",
        "#PRINT\n",
        "for i in range (10):\n",
        "  print(data[i])\n",
        "\n",
        "print()\n",
        "print(\"AVG:\")\n",
        "print(\"epochs = \", avg_epochs4, \"train loss = \", avg_train_loss, \"validation loss= \", avg_validation_loss)\n",
        "\n",
        "print()\n",
        "print(\"STD:\")\n",
        "print(\"epochs = \", std_epochs4, \"train loss = \", std_train_loss, \"validation loss= \", std_validation_loss)\n",
        "\n",
        "print()\n",
        "print(\"failed tries = \", fail_counter)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2206, tensor(0.1994, grad_fn=<NegBackward>), tensor(0.0633, grad_fn=<NegBackward>))\n",
            "(724, tensor(0.1999, grad_fn=<NegBackward>), tensor(0.0705, grad_fn=<NegBackward>))\n",
            "(578, tensor(0.2000, grad_fn=<NegBackward>), tensor(0.0702, grad_fn=<NegBackward>))\n",
            "(644, tensor(0.1996, grad_fn=<NegBackward>), tensor(0.0695, grad_fn=<NegBackward>))\n",
            "(1800, tensor(0.1997, grad_fn=<NegBackward>), tensor(0.0642, grad_fn=<NegBackward>))\n",
            "(786, tensor(0.1998, grad_fn=<NegBackward>), tensor(0.0671, grad_fn=<NegBackward>))\n",
            "(647, tensor(0.1998, grad_fn=<NegBackward>), tensor(0.0705, grad_fn=<NegBackward>))\n",
            "(717, tensor(0.1998, grad_fn=<NegBackward>), tensor(0.0693, grad_fn=<NegBackward>))\n",
            "(719, tensor(0.1998, grad_fn=<NegBackward>), tensor(0.0695, grad_fn=<NegBackward>))\n",
            "(907, tensor(0.1998, grad_fn=<NegBackward>), tensor(0.0745, grad_fn=<NegBackward>))\n",
            "\n",
            "AVG:\n",
            "epochs =  972.8 train loss =  0.06886293 validation loss=  0.19976097\n",
            "\n",
            "STD:\n",
            "epochs =  529.7298934362682 train loss =  0.0030933411 validation loss=  0.0001545313\n",
            "\n",
            "failed tries =  14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MaSoo7f-uEU"
      },
      "source": [
        "ניסוי 5\n",
        "\n",
        "Learning rate = 0.01 , k = 4 , Bypass= True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiQEkq1nD9rW",
        "outputId": "47f76262-8c87-428a-8a48-722d4591d121"
      },
      "source": [
        "k5 = 4\n",
        "Learning_rate5 = 0.01\n",
        "bypass5 = True\n",
        "\n",
        "counter = 0\n",
        "fail_counter = 0\n",
        "data = {}\n",
        "list_epochs = []\n",
        "list_train_loss = []\n",
        "list_validation_loss = []\n",
        "\n",
        "while counter < 10:\n",
        "    (succes, num_epochs, validation_loss, train_loss) = expiriment(k5, Learning_rate5, bypass5)\n",
        "    if succes == 1:\n",
        "      data[counter] =  (num_epochs, validation_loss, train_loss)\n",
        "      list_epochs.append(num_epochs)\n",
        "      list_train_loss.append(train_loss.detach().numpy())\n",
        "      list_validation_loss.append(validation_loss.detach().numpy())\n",
        "      counter +=1\n",
        "    else:\n",
        "      fail_counter +=1\n",
        "\n",
        "#AVG\n",
        "avg_epochs5 = np.average(list_epochs)\n",
        "avg_train_loss = np.average(list_train_loss)\n",
        "avg_validation_loss = np.average(list_validation_loss)\n",
        "\n",
        "#STD\n",
        "std_epochs5 = np.std(list_epochs)\n",
        "std_train_loss = np.std(list_train_loss)\n",
        "std_validation_loss = np.std(list_validation_loss)\n",
        "\n",
        "#PRINT\n",
        "for i in range (10):\n",
        "  print(data[i])\n",
        "\n",
        "print()\n",
        "print(\"AVG:\")\n",
        "print(\"epochs = \", avg_epochs5, \"train loss = \", avg_train_loss, \"validation loss= \", avg_validation_loss)\n",
        "\n",
        "print()\n",
        "print(\"STD:\")\n",
        "print(\"epochs = \", std_epochs5, \"train loss = \", std_train_loss, \"validation loss= \", std_validation_loss)\n",
        "\n",
        "print()\n",
        "print(\"failed tries = \", fail_counter)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7840, tensor(0.2000, grad_fn=<NegBackward>), tensor(0.0505, grad_fn=<NegBackward>))\n",
            "(8899, tensor(0.2000, grad_fn=<NegBackward>), tensor(0.0473, grad_fn=<NegBackward>))\n",
            "(6530, tensor(0.2000, grad_fn=<NegBackward>), tensor(0.0603, grad_fn=<NegBackward>))\n",
            "(11599, tensor(0.2000, grad_fn=<NegBackward>), tensor(0.0424, grad_fn=<NegBackward>))\n",
            "(8606, tensor(0.2000, grad_fn=<NegBackward>), tensor(0.0508, grad_fn=<NegBackward>))\n",
            "(6348, tensor(0.2000, grad_fn=<NegBackward>), tensor(0.0568, grad_fn=<NegBackward>))\n",
            "(6426, tensor(0.2000, grad_fn=<NegBackward>), tensor(0.0565, grad_fn=<NegBackward>))\n",
            "(11451, tensor(0.2000, grad_fn=<NegBackward>), tensor(0.0431, grad_fn=<NegBackward>))\n",
            "(6738, tensor(0.2000, grad_fn=<NegBackward>), tensor(0.0608, grad_fn=<NegBackward>))\n",
            "(10661, tensor(0.2000, grad_fn=<NegBackward>), tensor(0.0429, grad_fn=<NegBackward>))\n",
            "\n",
            "AVG:\n",
            "epochs =  8509.8 train loss =  0.051139165 validation loss=  0.19998252\n",
            "\n",
            "STD:\n",
            "epochs =  1987.5946166157726 train loss =  0.006799445 validation loss=  1.1375201e-05\n",
            "\n",
            "failed tries =  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HS2DRsMh-zpv"
      },
      "source": [
        "ניסוי 6\n",
        "\n",
        "Learning rate = 0.01 , k = 4 , Bypass= False"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHgINLicECk1",
        "outputId": "20195784-4ac8-4985-c99e-1fddc78f041f"
      },
      "source": [
        "k6 = 4\n",
        "Learning_rate6 = 0.01\n",
        "bypass6 = False\n",
        "\n",
        "counter = 0\n",
        "fail_counter = 0\n",
        "data = {}\n",
        "list_epochs = []\n",
        "list_train_loss = []\n",
        "list_validation_loss = []\n",
        "\n",
        "while counter < 10:\n",
        "    (succes, num_epochs, validation_loss, train_loss) = expiriment(k6, Learning_rate6, bypass6)\n",
        "    if succes == 1:\n",
        "      data[counter] =  (num_epochs, validation_loss, train_loss)\n",
        "      list_epochs.append(num_epochs)\n",
        "      list_train_loss.append(train_loss.detach().numpy())\n",
        "      list_validation_loss.append(validation_loss.detach().numpy())\n",
        "      counter +=1\n",
        "    else:\n",
        "      fail_counter +=1\n",
        "\n",
        "#AVG\n",
        "avg_epochs6 = np.average(list_epochs)\n",
        "avg_train_loss = np.average(list_train_loss)\n",
        "avg_validation_loss = np.average(list_validation_loss)\n",
        "\n",
        "#STD\n",
        "std_epochs6 = np.std(list_epochs)\n",
        "std_train_loss = np.std(list_train_loss)\n",
        "std_validation_loss = np.std(list_validation_loss)\n",
        "\n",
        "#PRINT\n",
        "for i in range (10):\n",
        "  print(data[i])\n",
        "\n",
        "print()\n",
        "print(\"AVG:\")\n",
        "print(\"epochs = \", avg_epochs6, \"train loss = \", avg_train_loss, \"validation loss= \", avg_validation_loss)\n",
        "\n",
        "print()\n",
        "print(\"STD:\")\n",
        "print(\"epochs = \", std_epochs6, \"train loss = \", std_train_loss, \"validation loss= \", std_validation_loss)\n",
        "\n",
        "print()\n",
        "print(\"failed tries = \", fail_counter)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5602, tensor(0.2000, grad_fn=<NegBackward>), tensor(0.0663, grad_fn=<NegBackward>))\n",
            "(5737, tensor(0.1999, grad_fn=<NegBackward>), tensor(0.0660, grad_fn=<NegBackward>))\n",
            "(6670, tensor(0.2000, grad_fn=<NegBackward>), tensor(0.0686, grad_fn=<NegBackward>))\n",
            "(6492, tensor(0.2000, grad_fn=<NegBackward>), tensor(0.0696, grad_fn=<NegBackward>))\n",
            "(8359, tensor(0.2000, grad_fn=<NegBackward>), tensor(0.0677, grad_fn=<NegBackward>))\n",
            "(6430, tensor(0.2000, grad_fn=<NegBackward>), tensor(0.0694, grad_fn=<NegBackward>))\n",
            "(6566, tensor(0.2000, grad_fn=<NegBackward>), tensor(0.0687, grad_fn=<NegBackward>))\n",
            "(7888, tensor(0.2000, grad_fn=<NegBackward>), tensor(0.0720, grad_fn=<NegBackward>))\n",
            "(6323, tensor(0.2000, grad_fn=<NegBackward>), tensor(0.0694, grad_fn=<NegBackward>))\n",
            "(6765, tensor(0.2000, grad_fn=<NegBackward>), tensor(0.0697, grad_fn=<NegBackward>))\n",
            "\n",
            "AVG:\n",
            "epochs =  6683.2 train loss =  0.068745375 validation loss=  0.19996853\n",
            "\n",
            "STD:\n",
            "epochs =  810.8729616900542 train loss =  0.001658752 validation loss=  1.3809821e-05\n",
            "\n",
            "failed tries =  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvmleSBq-4u0"
      },
      "source": [
        "ניסוי 7\n",
        "\n",
        "Learning rate = 0.01 , k = 2 , Bypass=True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UJSe5d_EFvU",
        "outputId": "cbb748b6-24fc-49bb-c09d-61dea2a89dbe"
      },
      "source": [
        "k7 = 2\n",
        "Learning_rate7 = 0.01\n",
        "bypass7 = True\n",
        "\n",
        "counter = 0\n",
        "fail_counter = 0\n",
        "data = {}\n",
        "list_epochs = []\n",
        "list_train_loss = []\n",
        "list_validation_loss = []\n",
        "\n",
        "while counter < 10:\n",
        "    (succes, num_epochs, validation_loss, train_loss) = expiriment(k7, Learning_rate7, bypass7)\n",
        "    if succes == 1:\n",
        "      data[counter] =  (num_epochs, validation_loss, train_loss)\n",
        "      list_epochs.append(num_epochs)\n",
        "      list_train_loss.append(train_loss.detach().numpy())\n",
        "      list_validation_loss.append(validation_loss.detach().numpy())\n",
        "      counter +=1\n",
        "    else:\n",
        "      fail_counter +=1\n",
        "\n",
        "#AVG\n",
        "avg_epochs7 = np.average(list_epochs)\n",
        "avg_train_loss = np.average(list_train_loss)\n",
        "avg_validation_loss = np.average(list_validation_loss)\n",
        "\n",
        "#STD\n",
        "std_epochs7 = np.std(list_epochs)\n",
        "std_train_loss = np.std(list_train_loss)\n",
        "std_validation_loss = np.std(list_validation_loss)\n",
        "\n",
        "#PRINT\n",
        "for i in range (10):\n",
        "  print(data[i])\n",
        "\n",
        "print()\n",
        "print(\"AVG:\")\n",
        "print(\"epochs = \", avg_epochs7, \"train loss = \", avg_train_loss, \"validation loss= \", avg_validation_loss)\n",
        "\n",
        "print()\n",
        "print(\"STD:\")\n",
        "print(\"epochs = \", std_epochs7, \"train loss = \", std_train_loss, \"validation loss= \", std_validation_loss)\n",
        "\n",
        "print()\n",
        "print(\"failed tries = \", fail_counter)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10397, tensor(0.2000, grad_fn=<NegBackward>), tensor(0.0491, grad_fn=<NegBackward>))\n",
            "(15145, tensor(0.2000, grad_fn=<NegBackward>), tensor(0.0456, grad_fn=<NegBackward>))\n",
            "(11029, tensor(0.2000, grad_fn=<NegBackward>), tensor(0.0509, grad_fn=<NegBackward>))\n",
            "(13987, tensor(0.2000, grad_fn=<NegBackward>), tensor(0.0457, grad_fn=<NegBackward>))\n",
            "(12167, tensor(0.2000, grad_fn=<NegBackward>), tensor(0.0426, grad_fn=<NegBackward>))\n",
            "(7627, tensor(0.2000, grad_fn=<NegBackward>), tensor(0.0542, grad_fn=<NegBackward>))\n",
            "(8018, tensor(0.2000, grad_fn=<NegBackward>), tensor(0.0591, grad_fn=<NegBackward>))\n",
            "(15657, tensor(0.2000, grad_fn=<NegBackward>), tensor(0.0458, grad_fn=<NegBackward>))\n",
            "(13923, tensor(0.2000, grad_fn=<NegBackward>), tensor(0.0483, grad_fn=<NegBackward>))\n",
            "(9393, tensor(0.2000, grad_fn=<NegBackward>), tensor(0.0516, grad_fn=<NegBackward>))\n",
            "\n",
            "AVG:\n",
            "epochs =  11734.3 train loss =  0.049287193 validation loss=  0.19998738\n",
            "\n",
            "STD:\n",
            "epochs =  2748.1093155113026 train loss =  0.004611089 validation loss=  8.666523e-06\n",
            "\n",
            "failed tries =  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eMmxXal-9aV"
      },
      "source": [
        "ניסוי 8\n",
        "\n",
        "Learning rate = 0.01 , k = 2 , Bypass= Flase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-Y8GorEEJt-",
        "outputId": "e235db3c-6bc0-4c46-9b7a-8229a2106233"
      },
      "source": [
        "k8 = 2\n",
        "Learning_rate8 = 0.01\n",
        "bypass8 = False\n",
        "\n",
        "counter = 0\n",
        "fail_counter = 0\n",
        "data = {}\n",
        "list_epochs = []\n",
        "list_train_loss = []\n",
        "list_validation_loss = []\n",
        "\n",
        "while counter < 10:\n",
        "    (succes, num_epochs, validation_loss, train_loss) = expiriment(k8, Learning_rate8, bypass8)\n",
        "    if succes == 1:\n",
        "      data[counter] =  (num_epochs, validation_loss, train_loss)\n",
        "      list_epochs.append(num_epochs)\n",
        "      list_train_loss.append(train_loss.detach().numpy())\n",
        "      list_validation_loss.append(validation_loss.detach().numpy())\n",
        "      counter +=1\n",
        "    else:\n",
        "      fail_counter +=1\n",
        "\n",
        "#AVG\n",
        "avg_epochs8 = np.average(list_epochs)\n",
        "avg_train_loss = np.average(list_train_loss)\n",
        "avg_validation_loss = np.average(list_validation_loss)\n",
        "\n",
        "#STD\n",
        "std_epochs8 = np.std(list_epochs)\n",
        "std_train_loss = np.std(list_train_loss)\n",
        "std_validation_loss = np.std(list_validation_loss)\n",
        "\n",
        "#PRINT\n",
        "for i in range (10):\n",
        "  print(data[i])\n",
        "\n",
        "print()\n",
        "print(\"AVG:\")\n",
        "print(\"epochs = \", avg_epochs8, \"train loss = \", avg_train_loss, \"validation loss= \", avg_validation_loss)\n",
        "\n",
        "print()\n",
        "print(\"STD:\")\n",
        "print(\"epochs = \", std_epochs8, \"train loss = \", std_train_loss, \"validation loss= \", std_validation_loss)\n",
        "\n",
        "print()\n",
        "print(\"failed tries = \", fail_counter)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7807, tensor(0.2000, grad_fn=<NegBackward>), tensor(0.0698, grad_fn=<NegBackward>))\n",
            "(6944, tensor(0.2000, grad_fn=<NegBackward>), tensor(0.0696, grad_fn=<NegBackward>))\n",
            "(6184, tensor(0.2000, grad_fn=<NegBackward>), tensor(0.0695, grad_fn=<NegBackward>))\n",
            "(8177, tensor(0.2000, grad_fn=<NegBackward>), tensor(0.0682, grad_fn=<NegBackward>))\n",
            "(6748, tensor(0.2000, grad_fn=<NegBackward>), tensor(0.0692, grad_fn=<NegBackward>))\n",
            "(6044, tensor(0.2000, grad_fn=<NegBackward>), tensor(0.0704, grad_fn=<NegBackward>))\n",
            "(5713, tensor(0.2000, grad_fn=<NegBackward>), tensor(0.0699, grad_fn=<NegBackward>))\n",
            "(7989, tensor(0.2000, grad_fn=<NegBackward>), tensor(0.0705, grad_fn=<NegBackward>))\n",
            "(5461, tensor(0.2000, grad_fn=<NegBackward>), tensor(0.0704, grad_fn=<NegBackward>))\n",
            "(6089, tensor(0.2000, grad_fn=<NegBackward>), tensor(0.0705, grad_fn=<NegBackward>))\n",
            "\n",
            "AVG:\n",
            "epochs =  6715.6 train loss =  0.0697964 validation loss=  0.1999819\n",
            "\n",
            "STD:\n",
            "epochs =  933.1188777428094 train loss =  0.00070526765 validation loss=  1.3556396e-05\n",
            "\n",
            "failed tries =  5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mf5beTW4_OlF"
      },
      "source": [
        "ניסוי 9 \n",
        "\n",
        "Learning rate = 0.1 , k = 1 , Bypass= True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdiFCqM1ENNV",
        "outputId": "f7519382-66fa-4162-ea63-63021e18bbe9"
      },
      "source": [
        "k9 = 1\n",
        "Learning_rate9 = 0.1\n",
        "bypass9 = True\n",
        "\n",
        "counter = 0\n",
        "fail_counter = 0\n",
        "data = {}\n",
        "list_epochs = []\n",
        "list_train_loss = []\n",
        "list_validation_loss = []\n",
        "\n",
        "while counter < 10:\n",
        "    (succes, num_epochs, validation_loss, train_loss) = expiriment(k9, Learning_rate9, bypass9)\n",
        "    if succes == 1:\n",
        "      data[counter] =  (num_epochs, validation_loss, train_loss)\n",
        "      list_epochs.append(num_epochs)\n",
        "      list_train_loss.append(train_loss.detach().numpy())\n",
        "      list_validation_loss.append(validation_loss.detach().numpy())\n",
        "      counter +=1\n",
        "    else:\n",
        "      fail_counter +=1\n",
        "\n",
        "#AVG\n",
        "avg_epochs9 = np.average(list_epochs)\n",
        "avg_train_loss = np.average(list_train_loss)\n",
        "avg_validation_loss = np.average(list_validation_loss)\n",
        "\n",
        "#STD\n",
        "std_epochs9 = np.std(list_epochs)\n",
        "std_train_loss = np.std(list_train_loss)\n",
        "std_validation_loss = np.std(list_validation_loss)\n",
        "\n",
        "#PRINT\n",
        "for i in range (10):\n",
        "  print(data[i])\n",
        "\n",
        "print()\n",
        "print(\"AVG:\")\n",
        "print(\"epochs = \", avg_epochs9, \"train loss = \", avg_train_loss, \"validation loss= \", avg_validation_loss)\n",
        "\n",
        "print()\n",
        "print(\"STD:\")\n",
        "print(\"epochs = \", std_epochs9, \"train loss = \", std_train_loss, \"validation loss= \", std_validation_loss)\n",
        "\n",
        "print()\n",
        "print(\"failed tries = \", fail_counter)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0238],\n",
            "        [0.9923],\n",
            "        [0.9923],\n",
            "        [1.0000],\n",
            "        [0.9967],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9923]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0238],\n",
            "        [0.9923],\n",
            "        [0.9923],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0238],\n",
            "        [0.9923],\n",
            "        [0.9923],\n",
            "        [1.0000],\n",
            "        [0.9967],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9923]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0238],\n",
            "        [0.9923],\n",
            "        [0.9923],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0238],\n",
            "        [0.9923],\n",
            "        [0.9923],\n",
            "        [1.0000],\n",
            "        [0.9967],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9923]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0238],\n",
            "        [0.9923],\n",
            "        [0.9923],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0238],\n",
            "        [0.9923],\n",
            "        [0.9923],\n",
            "        [1.0000],\n",
            "        [0.9967],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9923]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0238],\n",
            "        [0.9923],\n",
            "        [0.9923],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0238],\n",
            "        [0.9923],\n",
            "        [0.9923],\n",
            "        [1.0000],\n",
            "        [0.9967],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9923]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0238],\n",
            "        [0.9923],\n",
            "        [0.9923],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0238],\n",
            "        [0.9923],\n",
            "        [0.9923],\n",
            "        [1.0000],\n",
            "        [0.9967],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9923]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0238],\n",
            "        [0.9923],\n",
            "        [0.9923],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0238],\n",
            "        [0.9923],\n",
            "        [0.9923],\n",
            "        [1.0000],\n",
            "        [0.9967],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9923]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0238],\n",
            "        [0.9923],\n",
            "        [0.9923],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0238],\n",
            "        [0.9923],\n",
            "        [0.9923],\n",
            "        [1.0000],\n",
            "        [0.9967],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9923]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0238],\n",
            "        [0.9923],\n",
            "        [0.9923],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0238],\n",
            "        [0.9923],\n",
            "        [0.9923],\n",
            "        [1.0000],\n",
            "        [0.9967],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9923]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0238],\n",
            "        [0.9923],\n",
            "        [0.9923],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0238],\n",
            "        [0.9923],\n",
            "        [0.9923],\n",
            "        [1.0000],\n",
            "        [0.9967],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9923]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0238],\n",
            "        [0.9923],\n",
            "        [0.9923],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0238],\n",
            "        [0.9923],\n",
            "        [0.9923],\n",
            "        [1.0000],\n",
            "        [0.9967],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9923]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0238],\n",
            "        [0.9923],\n",
            "        [0.9923],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0237],\n",
            "        [0.9923],\n",
            "        [0.9923],\n",
            "        [1.0000],\n",
            "        [0.9967],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9923]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0237],\n",
            "        [0.9923],\n",
            "        [0.9923],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0237],\n",
            "        [0.9923],\n",
            "        [0.9923],\n",
            "        [1.0000],\n",
            "        [0.9967],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9923]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0237],\n",
            "        [0.9923],\n",
            "        [0.9923],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0237],\n",
            "        [0.9923],\n",
            "        [0.9923],\n",
            "        [1.0000],\n",
            "        [0.9967],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9923]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0237],\n",
            "        [0.9923],\n",
            "        [0.9923],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0237],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000],\n",
            "        [0.9967],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9924]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0237],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0237],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000],\n",
            "        [0.9967],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9924]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0237],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0237],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000],\n",
            "        [0.9967],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9924]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0237],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0237],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000],\n",
            "        [0.9967],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9924]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0237],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0237],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000],\n",
            "        [0.9967],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9924]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0237],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0237],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9924]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0237],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0237],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9924]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0237],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0237],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9924]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0237],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0237],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9924]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0237],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0236],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9924]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0236],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0236],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9924]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0236],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0236],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9924]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0236],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0236],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9924]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0236],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0236],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9924]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0236],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0236],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9924]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0236],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0236],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9924]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0236],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0236],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9924]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0236],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0236],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9924]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0236],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0236],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9924]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0236],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0236],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9924]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0236],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0236],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9924]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0236],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0235],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9924]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0235],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0235],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9924]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0235],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0235],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9924]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0235],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0235],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9924]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0235],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0235],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9924]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0235],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0235],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9924]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0235],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0235],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9924]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0235],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0235],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9924]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0235],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0235],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9924]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0235],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0235],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9924]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0235],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0235],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9924]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0235],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0235],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9924]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0235],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0235],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9924]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0235],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0234],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9924]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0234],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0234],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9924]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0234],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0234],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9924]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0234],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0234],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9924]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0234],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0234],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9924]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0234],\n",
            "        [0.9924],\n",
            "        [0.9924],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0234],\n",
            "        [0.9924],\n",
            "        [0.9925],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9924]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0234],\n",
            "        [0.9924],\n",
            "        [0.9925],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0234],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9925]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0234],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0234],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9925]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0234],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0234],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9925]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0234],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0234],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9925]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0234],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0234],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9925]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0234],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0234],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9925]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0234],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0233],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9925]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0233],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0233],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9925]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0233],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0233],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9925]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0233],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0233],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9925]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0233],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0233],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9925]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0233],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0233],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9925]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0233],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0233],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9925]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0233],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0233],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9925]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0233],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0233],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9925]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0233],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0233],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9925]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0233],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0233],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9925]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0233],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0233],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9925]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0233],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0233],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9925]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0233],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0232],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9925]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0232],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0232],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9925]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0232],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0232],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9925]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0232],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0232],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9925]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0232],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0232],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9925]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0232],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0232],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9925]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0232],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0232],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9925]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0232],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0232],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9925]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0232],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0232],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9925]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0232],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0232],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9925]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0232],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0232],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9925]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0232],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0232],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9925]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0232],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0232],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9925]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0232],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0231],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9925]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0231],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0231],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9925]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0231],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0231],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9925]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0231],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0231],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9925]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0231],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0231],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9925]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0231],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0231],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9925]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0231],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0231],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9925]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0231],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0231],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9925]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0231],\n",
            "        [0.9925],\n",
            "        [0.9925],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0231],\n",
            "        [0.9925],\n",
            "        [0.9926],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9925]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0231],\n",
            "        [0.9925],\n",
            "        [0.9926],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0231],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9926]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0231],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0231],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9926]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0231],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0231],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000],\n",
            "        [0.9968],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9926]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0231],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0231],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9926]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0231],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0230],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9926]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0230],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0230],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9926]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0230],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0230],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9926]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0230],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0230],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9926]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0230],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0230],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9926]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0230],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0230],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9926]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0230],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0230],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9926]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0230],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0230],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9926]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0230],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0230],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9926]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0230],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0230],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9926]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0230],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0230],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9926]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0230],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0230],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9926]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0230],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0230],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9926]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0230],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0230],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9926]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0230],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0229],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9926]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0229],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0229],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9926]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0229],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0229],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9926]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0229],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0229],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9926]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0229],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0229],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9926]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0229],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0229],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9926]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0229],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0229],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9926]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0229],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0229],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9926]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0229],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0229],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9926]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0229],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0229],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9926]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0229],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0229],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9926]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0229],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0229],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9926]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0229],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0229],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9926]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0229],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0228],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9926]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0228],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0228],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9926]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0228],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0228],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9926]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0228],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0228],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9926]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0228],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0228],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9926]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0228],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0228],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9926]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0228],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0228],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9926]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0228],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0228],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9926]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0228],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0228],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9926]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0228],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0228],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9926]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0228],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0228],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9926]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0228],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0228],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9926]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0228],\n",
            "        [0.9926],\n",
            "        [0.9926],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0228],\n",
            "        [0.9926],\n",
            "        [0.9927],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9926]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0228],\n",
            "        [0.9926],\n",
            "        [0.9927],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0228],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9927]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0228],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0227],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9927]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0227],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0227],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9927]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0227],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0227],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9927]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0227],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0227],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9927]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0227],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0227],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9927]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0227],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0227],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9927]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0227],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0227],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9927]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0227],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0227],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9927]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0227],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0227],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9927]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0227],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0227],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9927]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0227],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0227],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9927]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0227],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0227],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9927]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0227],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0227],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9927]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0227],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0227],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9927]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0227],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0226],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9927]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0226],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0226],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9927]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0226],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0226],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9927]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0226],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0226],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9927]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0226],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0226],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9927]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0226],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0226],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9927]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0226],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0226],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9927]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0226],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0226],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9927]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0226],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0226],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9927]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0226],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0226],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9927]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0226],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0226],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9927]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0226],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0226],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9927]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0226],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0226],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9927]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0226],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0226],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9927]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0226],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0226],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9927]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0226],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0225],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9927]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0225],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0225],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9927]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0225],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0225],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9927]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0225],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0225],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9927]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0225],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0225],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9927]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0225],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0225],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9927]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0225],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0225],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9927]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0225],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0225],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9927]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0225],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0225],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9927]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0225],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0225],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9927]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0225],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0225],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9927]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0225],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0225],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9927]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0225],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0225],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9927]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0225],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0225],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9927]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0225],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0224],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9927]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0224],\n",
            "        [0.9927],\n",
            "        [0.9927],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0224],\n",
            "        [0.9927],\n",
            "        [0.9928],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9928]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0224],\n",
            "        [0.9927],\n",
            "        [0.9928],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0224],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000],\n",
            "        [0.9969],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9928]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0224],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0224],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000],\n",
            "        [0.9970],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9928]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0224],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0224],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000],\n",
            "        [0.9970],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9928]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0224],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0224],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000],\n",
            "        [0.9970],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9928]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0224],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0224],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000],\n",
            "        [0.9970],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9928]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0224],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0224],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000],\n",
            "        [0.9970],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9928]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0224],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0224],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000],\n",
            "        [0.9970],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9928]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0224],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0224],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000],\n",
            "        [0.9970],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9928]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0224],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0224],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000],\n",
            "        [0.9970],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9928]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0224],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0224],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000],\n",
            "        [0.9970],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9928]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0224],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0224],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000],\n",
            "        [0.9970],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9928]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0224],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0224],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000],\n",
            "        [0.9970],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9928]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0224],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0224],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000],\n",
            "        [0.9970],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9928]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0224],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0223],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000],\n",
            "        [0.9970],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9928]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0223],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0223],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000],\n",
            "        [0.9970],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9928]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0223],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0223],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000],\n",
            "        [0.9970],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9928]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0223],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0223],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000],\n",
            "        [0.9970],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9928]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0223],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0223],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000],\n",
            "        [0.9970],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9928]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0223],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0223],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000],\n",
            "        [0.9970],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9928]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0223],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0223],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000],\n",
            "        [0.9970],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9928]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0223],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0223],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000],\n",
            "        [0.9970],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9928]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0223],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0223],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000],\n",
            "        [0.9970],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9928]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0223],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0223],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000],\n",
            "        [0.9970],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9928]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0223],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0223],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000],\n",
            "        [0.9970],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9928]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0223],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0223],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000],\n",
            "        [0.9970],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9928]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0223],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0223],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000],\n",
            "        [0.9970],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9928]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0223],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0223],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000],\n",
            "        [0.9970],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9928]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0223],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0223],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000],\n",
            "        [0.9970],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9928]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0223],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0222],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000],\n",
            "        [0.9970],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9928]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0222],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0222],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000],\n",
            "        [0.9970],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9928]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0222],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0222],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000],\n",
            "        [0.9970],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9928]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0222],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0222],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000],\n",
            "        [0.9970],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9928]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0222],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0222],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000],\n",
            "        [0.9970],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9928]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0222],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0222],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000],\n",
            "        [0.9970],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9928]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0222],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0222],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000],\n",
            "        [0.9970],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9928]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0222],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0222],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000],\n",
            "        [0.9970],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9928]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0222],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0222],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000],\n",
            "        [0.9970],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9928]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0222],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0222],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000],\n",
            "        [0.9970],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9928]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0222],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0222],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000],\n",
            "        [0.9970],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9928]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0222],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0222],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000],\n",
            "        [0.9970],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9928]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0222],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0222],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000],\n",
            "        [0.9970],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9928]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])  -->  tensor([[0.0222],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 1.0000],\n",
            "        [1.0000, 0.1000],\n",
            "        [1.0000, 0.9000],\n",
            "        [0.9000, 0.9000],\n",
            "        [0.1000, 0.9000]])  -->  tensor([[0.0222],\n",
            "        [0.9928],\n",
            "        [0.9928],\n",
            "        [1.0000],\n",
            "        [0.9970],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9928]], grad_fn=<MulBackward0>)\n",
            "(1494, tensor(0.1999, grad_fn=<NegBackward>), tensor(0.0459, grad_fn=<NegBackward>))\n",
            "(1656, tensor(0.1999, grad_fn=<NegBackward>), tensor(0.0459, grad_fn=<NegBackward>))\n",
            "(1556, tensor(0.2000, grad_fn=<NegBackward>), tensor(0.0459, grad_fn=<NegBackward>))\n",
            "(1508, tensor(0.2000, grad_fn=<NegBackward>), tensor(0.0459, grad_fn=<NegBackward>))\n",
            "(1590, tensor(0.2000, grad_fn=<NegBackward>), tensor(0.0459, grad_fn=<NegBackward>))\n",
            "(1560, tensor(0.2000, grad_fn=<NegBackward>), tensor(0.0459, grad_fn=<NegBackward>))\n",
            "(1959, tensor(0.1999, grad_fn=<NegBackward>), tensor(0.0626, grad_fn=<NegBackward>))\n",
            "(1772, tensor(0.1999, grad_fn=<NegBackward>), tensor(0.0459, grad_fn=<NegBackward>))\n",
            "(1604, tensor(0.2000, grad_fn=<NegBackward>), tensor(0.0459, grad_fn=<NegBackward>))\n",
            "(1545, tensor(0.1999, grad_fn=<NegBackward>), tensor(0.0459, grad_fn=<NegBackward>))\n",
            "\n",
            "AVG:\n",
            "epochs =  1624.4 train loss =  0.047570683 validation loss=  0.19994661\n",
            "\n",
            "STD:\n",
            "epochs =  134.91641857090633 train loss =  0.0050069033 validation loss=  3.47256e-05\n",
            "\n",
            "failed tries =  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oz0v-VC2axJ3"
      },
      "source": [
        "היות ומדובר ברשת עם מעקף ולפונקציה יש 2 קלטים עבורם מתקבל 1 - תפקידו של הניורון הנסתר הוא לבצע פונקציות לוגיות שהן\n",
        "\n",
        "OR , AND\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMoUW9B-g6_s"
      },
      "source": [
        "סעיף ז - גרפים"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "sSPv5BNqg-_o",
        "outputId": "bda46680-4d22-4559-8ec8-3cc7d3174427"
      },
      "source": [
        "#GRAPHS\n",
        "all_epochs_avg = (avg_epochs1,avg_epochs2,avg_epochs3,avg_epochs4,avg_epochs5,avg_epochs6,avg_epochs7,avg_epochs8,avg_epochs9)\n",
        "all_k = (k1,k2,k3,k4,k5,k6,k7,k8,k9)\n",
        "all_bypass = (bypass1, bypass2,bypass3,bypass4,bypass5,bypass6,bypass7,bypass8,bypass9)\n",
        "all_lr = (Learning_rate1, Learning_rate2, Learning_rate3, Learning_rate4, Learning_rate5, Learning_rate6, Learning_rate7, Learning_rate8, Learning_rate9)\n",
        "all_std = (std_epochs1,std_epochs2,std_epochs3,std_epochs4,std_epochs5,std_epochs6,std_epochs7,std_epochs8,std_epochs9)\n",
        "\n",
        "# Plot 1\n",
        "plt.scatter(all_k, all_epochs_avg)\n",
        "plt.title('epochs and k')\n",
        "plt.xlabel('k')\n",
        "plt.ylabel('avg epochs')\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2cQPTX2-GXA"
      },
      "source": [
        "רואים בגרף מספר האיפוקים כתלות במספר הניורונים משתנה , קשה להסיק מסקנה מיידית מחוסר בשימוש בפיצ'רים נוספים. ניתן להניח שהמסקנה המיידית היא שככל שיש יותר ניורוים ניסתרים מספר האיפוקים קטן"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "YvYF8M18kcbp",
        "outputId": "9ddbb0e9-dd81-41b8-dddc-d30a0c288959"
      },
      "source": [
        "# Plot 2\n",
        "plt.scatter(all_bypass, all_epochs_avg)\n",
        "plt.title('epochs and bypass')\n",
        "plt.xlabel('bypass')\n",
        "plt.ylabel('avg epochs')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJyhEHPs-btZ"
      },
      "source": [
        "רואים בגרף מספר האיפוקים כתלות בהאם קיים מעקף או לא , קשה להסיק מסקנה מיידית מחוסר בשימוש בפיצ'רים נוספים . ניתן להניח שהמסקנה המיידית היא שכאשר יש מעקף מספר האיפוקים גדל"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "IT4dL_vkky0f",
        "outputId": "497aa88d-72ca-4064-8fc3-869c9b67e423"
      },
      "source": [
        "# Plot 3\n",
        "plt.scatter(all_lr, all_std)\n",
        "plt.title('learning rate and std epochs')\n",
        "plt.xlabel('learning rate')\n",
        "plt.ylabel('std epochs')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkfInBea-8Sr"
      },
      "source": [
        "רואים בגרף סטיית תקן של מספר האיפוקים כתלות בקבוע הלמידה ,   המסקנה המיידית היא שכאשר יש קבוע למידה גדול יותר מספר האיפוקים קטן"
      ]
    }
  ]
}